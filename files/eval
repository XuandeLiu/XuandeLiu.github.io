# src/eval.py
from __future__ import annotations
import os, argparse
import torch
from config import load_config, ensure_dirs
from utils.common import set_seed, device_auto, save_json
from utils.metrics import masked_r2_last
from models.deeplobv import DeepLOBv
from data.uam_threeway_prep import ThreeWayConfig, make_threeway_loaders

def main():
    parser = argparse.ArgumentParser()
    parser.add_argument('--config', type=str, default='configs/default.yaml')
    parser.add_argument('--ckpt', type=str, default='outputs/checkpoints/best.pt')
    args = parser.parse_args()

    cfg = load_config(args.config)
    ensure_dirs(cfg); set_seed(cfg['seed'])
    device = device_auto()

    # TODO: 替换为你的真实数据加载
    import pandas as pd; raise RuntimeError("请在 src/eval.py 中加载 training_df/testing_df，并构造 loaders 再运行。")

    # from data.uam_threeway_prep import ThreeWayConfig, make_threeway_loaders
    # dc = cfg['data']
    # twc = ThreeWayConfig(
    #     date_col=dc['date_col'], time_col=dc['time_col'], symbol_col=dc['symbol_col'], y_col=dc['y_col'],
    #     inner_split_date=dc['inner_split_date'], L_days=dc['L_days'], bars_per_day=dc['bars_per_day'],
    #     min_valid_ratio=dc['min_valid_ratio'], use_sparse=dc['use_sparse'],
    #     add_delta_g_feature=dc['add_delta_g_feature'], delta_cap=dc['delta_cap'],
    #     K_per_symbol=dc['K_per_symbol'], batch_size=dc['batch_size'],
    #     num_workers=dc['num_workers'], pin_memory=dc['pin_memory']
    # )
    # train_loader, inner_test_loader, outer_test_loader, meta = make_threeway_loaders(training_df, testing_df, twc)
    # model = DeepLOBv(in_features=meta['X'].shape[1], **cfg['model']).to(device)
    # state = torch.load(args.ckpt, map_location=device)
    # model.load_state_dict(state); model.eval()

    # def eval_loader(loader):
    #     r2_sum = 0.0; n_batch = 0
    #     with torch.no_grad():
    #         for xb, yb, mb in loader:
    #             xb, yb, mb = xb.to(device), yb.to(device), mb.to(device)
    #             yh = model(xb)
    #             r2_sum += masked_r2_last(yh, yb, mb).item(); n_batch += 1
    #     return r2_sum / max(1, n_batch)

    # r2_inner = eval_loader(inner_test_loader)
    # r2_outer = eval_loader(outer_test_loader)
    # print(f'Inner-split R2: {r2_inner:.6f} | Outer-test R2: {r2_outer:.6f}')

    # save_json({'r2_inner': r2_inner, 'r2_outer': r2_outer},
    #           os.path.join(cfg['paths']['metrics_dir'], 'eval_summary.json'))

if __name__ == '__main__':
    main()